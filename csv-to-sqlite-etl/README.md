# ğŸšš CSV to SQLite ETL Pipeline

This beginner-friendly project demonstrates a complete ETL pipeline using Python. The pipeline extracts shipment data from a CSV file, transforms (cleans) it, and loads it into a SQLite database for analysis.

---

## ğŸ“Š Use Case
A logistics company tracks its daily shipments via CSV logs. This project helps automate the process of loading those logs into a database for reporting.

---

## ğŸ›  Tools Used
- Python
- Pandas
- SQLite (via `sqlite3`)
- Modular ETL structure

---

## ğŸ“ Project Structure
```
â”œâ”€â”€ data/              # Raw CSV file
â”œâ”€â”€ etl/               # ETL scripts (extract, transform, load)
â”œâ”€â”€ output/            # Output SQLite DB file
â”œâ”€â”€ scenario.md        # Business context + objectives
â”œâ”€â”€ README.md          # This file
â””â”€â”€ requirements.txt   # Python dependencies
```
---

## ğŸš€ How to Run

### 1. Install dependencies

```bash
pip install -r requirements.txt
```
2. Run the full pipeline
```bash
cd etl
python load.py
```
After running, youâ€™ll find the SQLite database in:
```bash
output/shipments.db
```

ğŸ§ª Sample Query
```
SELECT destination, COUNT(*) as total_shipments
FROM shipments
GROUP BY destination
ORDER BY total_shipments DESC;
```