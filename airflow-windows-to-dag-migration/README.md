# ğŸŒ¬ï¸ Airflow DAG: Windows Scheduler Migration

This project demonstrates how to **migrate a Windows Task Scheduler job** into a **modular Apache Airflow DAG** using Python.

---

## ğŸ§  Scenario

A company previously ran a daily `.bat` or `.py` script using Windows Task Scheduler to copy files from a source folder to a backup directory.

---

## ğŸš€ What This DAG Does

âœ… Simulates the legacy Windows job using Airflow  
âœ… Backs up a file from `/tmp/data/input_file.csv` to `/tmp/backup/input_file_backup.csv`  
âœ… Leverages Airflowâ€™s built-in logging, retries, and scheduling  
âœ… Fully deployable on any Airflow instance via `PythonOperator`

---

## ğŸ“‚ Project Structure

```
data-engineering-portfolio/
â”œâ”€â”€ airflow-docker/
â”‚   â””â”€â”€ docker-airflow/
â”‚       â”œâ”€â”€ dags/
â”‚       â”‚   â””â”€â”€ windows_backup_dag.py
â”‚       â”œâ”€â”€ docker-compose-LocalExecutor.yml
â”‚       â””â”€â”€ â€¦
â”œâ”€â”€ airflow-windows-to-dag-migration/
â”‚   â”œâ”€â”€ dags/
â”‚   â”‚   â””â”€â”€ windows_backup_dag.py
â”‚   â”œâ”€â”€ tmp/
â”‚   â”‚   â”œâ”€â”€ data/input_file.csv
â”‚   â”‚   â””â”€â”€ backup/input_file_backup.csv
â”‚   â””â”€â”€ â€¦

```
---

## âš™ï¸ How It Works

- Airflow runs in Docker using **LocalExecutor**
- A DAG named `windows_backup_migration_dag` runs **daily**
- It copies:
  - From â†’ `/tmp/data/input_file.csv`
  - To â†’ `/tmp/backup/input_file_backup.csv`

---

## ğŸ³ Setup Instructions

1. Clone the repo and navigate to the project folder:

   ```bash
   cd airflow-docker/docker-airflow

2. Update volume mount in docker-compose-LocalExecutor.yml:
   
  volumes:
  
	  - ./dags:/usr/local/airflow/dags
	  - ../../airflow-windows-to-dag-migration/tmp:/usr/local/airflow/shared/tmp   

3. Start, Stop and Restart Airflow:
   
        Start Airflow:
        docker-compose -f docker-compose-LocalExecutor.yml up -d

        Stop Airflow:
        docker-compose -f docker-compose-LocalExecutor.yml down

        Restart Airflow:
        docker-compose -f docker-compose-LocalExecutor.yml restart

5.	Access Airflow UI
   
	â€¢	Visit: http://localhost:8080 or your GitHub Codespaces proxy URL
  
7.	Trigger the DAG:
   
	â€¢	Go to windows_backup_migration_dag
	â€¢	Turn it ON and trigger manually
	â€¢	Confirm that input_file_backup.csv is created


 ## ğŸ§© DAG Logic (Simplified)
 
	 src = '/usr/local/airflow/shared/tmp/data/input_file.csv'
 
	 dst = '/usr/local/airflow/shared/tmp/backup/input_file_backup.csv'
 
	 shutil.copyfile(src, dst)
 


  ## âœ… Outcome
 
âœ¨ Legacy Windows task is replaced with a modern, testable Airflow workflow

âœ¨ Daily file backup is handled via a DAG

âœ¨ Containerized setup ensures development and testing consistency


![Airflow DAG Screenshot](https://github.com/bashoori/repo/blob/master/airflow-windows-to-dag-migration/airflow.png?raw=true)


â¸»

ğŸ‘©â€ğŸ’» Author

Created by Bita Ashoori
Data Engineer | Cloud Enthusiast | Automation Advocate
